{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "import sys \n",
    "sys.path.append('../common')\n",
    "\n",
    "import sample_methods as s\n",
    "import nlp_modules as nm\n",
    "\n",
    "def generate(input):\n",
    "\n",
    "    MODEL_FILENAME = \"./w1d3_transformer_shakespeare.pt\"\n",
    "\n",
    "    model = t.load(MODEL_FILENAME, map_location=t.device('cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = nm.WordsTokenizer(16)\n",
    "    tokenizer.load_saved()\n",
    "\n",
    "    text_output = s.sample_tokens(model, tokenizer, input, max_tokens_generated=100, temperature=1.0, top_k=10)\n",
    "    return text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn down for what a brow,\\nIn the day that the should of thy that which.\\n  So it self beauty love that thou hast to me,\\nIn thy mind, or all, though for my love art,\\n  My that that beauty I shall be true,\\n  To let I have shall be be that thou the'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"turn down for what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7ff7d40ec370>, 'http://127.0.0.1:7861/', None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/gradio/routes.py\", line 289, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/gradio/blocks.py\", line 982, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator)\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/gradio/blocks.py\", line 824, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/envs/shk/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_14761/3319645153.py\", line 19, in generate\n",
      "    text_output = s.sample_tokens(model, tokenizer, input, max_tokens_generated=100, temperature=1.0, top_k=10)\n",
      "  File \"/workspaces/transformers-from-scratch/decoder_transformer/../common/sample_methods.py\", line 116, in sample_tokens\n",
      "    input_ids: list = tokenizer.encode(initial_text)\n",
      "  File \"/workspaces/transformers-from-scratch/decoder_transformer/../common/nlp_modules.py\", line 86, in encode\n",
      "    encoded = [self.word_id_map[word] for word in split_text]\n",
      "  File \"/workspaces/transformers-from-scratch/decoder_transformer/../common/nlp_modules.py\", line 86, in <listcomp>\n",
      "    encoded = [self.word_id_map[word] for word in split_text]\n",
      "KeyError: 'fucker'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=generate, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('shk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61cf45ea2041b4bb939fe103c85ae429341fda0fe9513e7286bdc8966ffebae2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
